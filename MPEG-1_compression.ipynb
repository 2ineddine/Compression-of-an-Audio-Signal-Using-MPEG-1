{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6c184a60",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "# $ MPEG-1 \\space Audio \\space Signal \\space Compression $\n",
    "$\\texttt{@2ineddine}$   \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c9bf760",
   "metadata": {},
   "source": [
    "# Preparation \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63cb1534",
   "metadata": {},
   "source": [
    "1. Maximum number of bits per frame:\n",
    "\n",
    "$$\n",
    "N_{b_{\\text{max}}} = \\frac{D}{N_{tr}}\n",
    "$$\n",
    "\n",
    "---\n",
    "\n",
    "2. - The latest possible starting index for a complete frame is:\n",
    "\n",
    "  $$\n",
    "  n_{\\text{max}} = F_s - N_{win}\n",
    "  $$\n",
    "\n",
    "- The valid starting indices for a complete frame are:\n",
    "\n",
    "  $$\n",
    "  n = 0, N_{hop}, 2N_{hop}, \\dots, kN_{hop} \\leq F_s - N_{win}\n",
    "  $$\n",
    "\n",
    "- This gives:\n",
    "\n",
    "  $$\n",
    "  k_{\\text{max}} = \\left\\lfloor \\frac{F_s - N_{win}}{N_{hop}} \\right\\rfloor\n",
    "  $$\n",
    "\n",
    "- Since we start at 0, the total number of frames is:\n",
    "\n",
    "  $$\n",
    "  L = k_{\\text{max}} + 1 = \\left\\lfloor \\frac{F_s - N_{win}}{N_{hop}} + 1 \\right\\rfloor\n",
    "  $$\n",
    "\n",
    "---\n",
    "\n",
    "3. Fractional number of **incomplete frames on the left** (start before $ x_1 $, end inside $ x_1 $):\n",
    "\n",
    "$$\n",
    "\\frac{(N_{win} - 1)K_1}{N_{win}} - \\frac{N_{hop}K_1(K_1 + 1)}{2N_{win}}, \\quad \\text{where} \\quad K_1 = \\left\\lfloor \\frac{N_{win} - 1}{N_{hop}} \\right\\rfloor\n",
    "$$\n",
    "\n",
    "- The first term represents the **sum of visible parts** of these frames inside $ x_1 $.\n",
    "- The second term corrects for the **progressive overlap** (the farther a frame starts, the less it is visible in $ x_1 $).\n",
    "\n",
    "---\n",
    "\n",
    "4. Fractional number of **incomplete frames on the right** (start in $ x_1 $, end after it):\n",
    "\n",
    "$$\n",
    "\\frac{K_2(F_s - (L - 1)N_{hop})}{N_{win}} - \\frac{N_{hop}K_2(K_2 + 1)}{2N_{win}}, \\quad \\text{where} \\quad K_2 = \\left\\lfloor \\frac{F_s - 1}{N_{hop}} - L + 1 \\right\\rfloor\n",
    "$$\n",
    "\n",
    "Some frames **start within** the window $ x_1 $, but **extend beyond** its end.  \n",
    "They are **incomplete on the right**, and **partially counted** in the total $ N_{tr} $.\n",
    "\n",
    "- First term: visible duration of these frames in $ x_1 $  \n",
    "- Second term: correction due to overlap\n",
    "\n",
    "---\n",
    "\n",
    "5. Total (fractional) number of frames in $ x_1 $ (over 1 s):\n",
    "\n",
    "$$\n",
    "N_{tr} = L + \\text{(fractional frames on the left)} + \\text{(fractional frames on the right)}\n",
    "$$\n",
    "\n",
    "---\n",
    "\n",
    "6.\n",
    "\n",
    "- Frames **on the left**:\n",
    "\n",
    "$$\n",
    "\\frac{(N_{win} - 1)K_1}{N_{win}} - \\frac{N_{hop}K_1(K_1 + 1)}{2N_{win}}, \\quad K_1 = \\left\\lfloor \\frac{N_{win} - 1}{N_{hop}} \\right\\rfloor\n",
    "$$\n",
    "\n",
    "- Frames **on the right**:\n",
    "\n",
    "$$\n",
    "\\frac{K_2(F_s - (L - 1)N_{hop})}{N_{win}} - \\frac{N_{hop}K_2(K_2 + 1)}{2N_{win}}, \\quad K_2 = \\left\\lfloor \\frac{F_s - 1}{N_{hop}} - L + 1 \\right\\rfloor\n",
    "$$\n",
    "\n",
    "Maximum number of bits per frame (final form with all parameters):\n",
    "\n",
    "$$\n",
    "N_{b_{\\text{max}}} = \\frac{D}{N_{tr}} = \\frac{D}{L + \\text{left} + \\text{right}}\n",
    "$$\n",
    "\n",
    "with $ L $ defined in question 2.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56f8d217",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Libraries\n",
    "from FourierCT import * \n",
    "from QuantCod  import *\n",
    "from Cod_inv import *\n",
    "import scipy.signal\n",
    "import scipy.io\n",
    "import scipy.io.wavfile as wavfile\n",
    "from scipy.signal import welch\n",
    "from scipy.io import wavfile\n",
    "import soundfile as sf\n",
    "import numpy as np\n",
    "import librosa\n",
    "import librosa.display\n",
    "import IPython.display as ipd\n",
    "from IPython.display import Audio, display\n",
    "import os\n",
    "import sounddevice as sd\n",
    "%matplotlib ipympl\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ced08c9",
   "metadata": {},
   "source": [
    "## Loading and Visualizing an Audio Signal with STFT Analysis\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46943f6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #1 /\n",
    "\n",
    "\n",
    "file_path = os.path.join(\"songs\", \"daftPunk_aroundTheWorld.wav\")\n",
    "Fs, x = wavfile.read(file_path)\n",
    "\n",
    "# Load the audio signal (x.wav)\n",
    "Fs, x = wavfile.read(\"songs/daftPunk_aroundTheWorld.wav\")  # Replace with your file\n",
    "if x.ndim > 1:\n",
    "    x = x[:, 0]  # keep one channel if stereo\n",
    "\n",
    "# Normalize if necessary (values between -1 and 1)\n",
    "x = x / np.max(np.abs(x))\n",
    "\n",
    "# Choose STFT parameters\n",
    "N_win = 2048      # window size (e.g., 1024 samples)\n",
    "N_hop = 1024      # hop size between windows\n",
    "Nfft = N_win      # FFT size\n",
    "\n",
    "# Compute STFT (via scipy’s STFT)\n",
    "x_mat, t_vect, freq_vect = TFCT(N_win, N_hop, Nfft, x, Fs)\n",
    "phase = np.angle(x_mat)  # phase\n",
    "\n",
    "# Display the spectrogram\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.pcolormesh(t_vect, freq_vect, 20 * np.log10(np.abs(x_mat) + 1e-10), shading='gouraud')\n",
    "plt.title(\"Spectrogram (STFT)\")\n",
    "plt.xlabel(\"Time (s)\")\n",
    "plt.ylabel(\"Frequency (Hz)\")\n",
    "plt.colorbar(label=\"Amplitude (dB)\")\n",
    "plt.ylim(0, 2500)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c8cb31e",
   "metadata": {},
   "source": [
    "## Normalizing Each STFT Frame by Its Maximum Amplitude\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad20e5d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #2\n",
    "\n",
    "x_mat_normalised = x_mat.copy()\n",
    "\n",
    "# Compute maximum amplitude for each column (frame)\n",
    "An = np.max(np.abs(x_mat_normalised), axis=0)\n",
    "\n",
    "# Normalize each column by its maximum amplitude\n",
    "x_mat_normalised = x_mat_normalised / An\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "713a3a69",
   "metadata": {},
   "source": [
    "## Bit Allocation per Frame and Frequency Bin in the STFT Domain\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c31ddcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Computing Bit Allocation per Frame and Frequency Bin\n",
    "\n",
    "D = 396 * 10**3  # Total number of bits available per second\n",
    "\n",
    "# Calculate the number of complete frames in 1 second\n",
    "L = int(np.floor((Fs - N_win) / N_hop + 1))\n",
    "\n",
    "# Incomplete frames on the left\n",
    "K1 = int(np.floor((N_win - 1) / N_hop))\n",
    "left = ((N_win - 1) * K1) / N_win - (N_hop * K1 * (K1 + 1)) / (2 * N_win)\n",
    "\n",
    "# Incomplete frames on the right\n",
    "K2 = int(np.floor((Fs - 1) / N_hop - L + 1))\n",
    "right = (K2 * (Fs - (L - 1) * N_hop)) / N_win - (N_hop * K2 * (K2 + 1)) / (2 * N_win)\n",
    "\n",
    "# Total (fractional) number of frames\n",
    "N_tr = L + left + right\n",
    "\n",
    "# Number of bits per frame\n",
    "Nb_trame = D / N_tr\n",
    "\n",
    "# Number of frequency points (FFT bins)\n",
    "N_f = N_win // 2 + 1\n",
    "\n",
    "# Number of bits per frequency bin\n",
    "Nb_point = Nb_trame / N_f\n",
    "\n",
    "# Display results\n",
    "print(\"Number of frames per second (N_tr):\", N_tr)\n",
    "print(\"Number of bits per frame (Nb_trame):\", Nb_trame)\n",
    "print(\"Number of bits per frequency bin (Nb_point):\", Nb_point)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cc7394f",
   "metadata": {},
   "source": [
    "## Bit Allocation Strategy Using Psychoacoustic Masking and Greedy Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "185be6f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters\n",
    "Nmax = np.ceil(Nb_trame)        # Total number of bits to allocate per frame\n",
    "Q_max = 16                      # Maximum number of bits per frequency bin\n",
    "mask_db = -96\n",
    "mask_lin = 10 ** (mask_db / 20)\n",
    "\n",
    "# x_mat_normalised and freq_vect must already be defined (from STFT)\n",
    "nb_freqs, nb_frames = x_mat_normalised.shape\n",
    "Q_all = np.zeros_like(x_mat_normalised.real, dtype=int)\n",
    "\n",
    "# Human auditory threshold (in Hz)\n",
    "threshold_hz = 25000  # we ignore frequencies above 25 kHz\n",
    "audible_indices = np.where(freq_vect <= threshold_hz)[0]  # indices to keep\n",
    "\n",
    "for n in range(nb_frames):\n",
    "    X_frame = np.abs(x_mat_normalised[:, n])  # Spectrum amplitude\n",
    "\n",
    "    # Compute SMR (Signal-to-Mask Ratio)\n",
    "    SMR = 20 * np.log10(X_frame / mask_lin + 1e-10)\n",
    "\n",
    "    # Initialize bit allocation\n",
    "    Q = np.zeros(nb_freqs, dtype=int)\n",
    "    SNR = np.zeros(nb_freqs)\n",
    "    NMR = SMR - SNR\n",
    "    Ndb = Nmax\n",
    "\n",
    "    # Greedy algorithm (on audible frequencies only)\n",
    "    while np.max(NMR[audible_indices]) > 0 and Ndb > 0:\n",
    "        i_local = np.argmax(NMR[audible_indices])   # index in audible range\n",
    "        i = audible_indices[i_local]                # actual index in the full spectrum\n",
    "\n",
    "        if Q[i] < Q_max:\n",
    "            Q[i] += 1\n",
    "            SNR[i] += 6\n",
    "            Ndb -= 1\n",
    "            NMR[i] = SMR[i] - SNR[i]\n",
    "        else:\n",
    "            NMR[i] = -np.inf  # ignore this frequency from now on\n",
    "\n",
    "    # Save allocation for this frame\n",
    "    Q_all[:, n] = Q\n",
    "\n",
    "print(\"Allocation complete: Q_all.shape =\", Q_all.shape)\n",
    "print(\"Remaining bits:\", Ndb)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed2bf677",
   "metadata": {},
   "source": [
    "##  Visualization of the Fuquant Quantization Function\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8418945",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #6\n",
    "\n",
    "x = np.linspace(-2, 2, 1000)\n",
    "y = np.array([Fuquant(xi, 10) for xi in x])  # Apply Fuquant to each input value\n",
    "\n",
    "plt.figure(np.random.randint(0, 1000), figsize=(10, 5))\n",
    "plt.plot(x, y, label=\"Quantized Output (Fuquant)\")\n",
    "plt.title(\"Characteristic Curve of the Fuquant Function\")\n",
    "plt.xlabel(\"Input x\")\n",
    "plt.ylabel(\"Quantized Output\")\n",
    "plt.grid(True)\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "daa7640b",
   "metadata": {},
   "source": [
    "The Fuquant function is used to transform a real number between –1 and +1 (such as 0.7 or –0.5) into a positive integer, so that it can be easily encoded using N bits through uniform quantization with saturation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16085d89",
   "metadata": {},
   "source": [
    "## Visualization of Original and Quantized Spectrograms in the STFT Domain\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f6a76ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute normalized quantized spectrum\n",
    "x_abs = np.abs(x_mat_normalised)\n",
    "nb_freqs, nb_frames = x_abs.shape\n",
    "\n",
    "Xq_norm = np.zeros_like(x_abs)\n",
    "\n",
    "for n in range(nb_frames):\n",
    "    for k in range(nb_freqs):\n",
    "        bits = Q_all[k, n]  # Use bit allocation matrix from greedy algorithm\n",
    "        if bits > 0:\n",
    "            Xq_norm[k, n] = Fuquant(x_abs[k, n], bits) / (2 ** (bits - 1) + 1e-10)\n",
    "        else:\n",
    "            Xq_norm[k, n] = 0  # No information transmitted\n",
    "\n",
    "# --- Plotting spectrograms ---\n",
    "plt.figure(np.random.randint(1000), figsize=(12, 5))\n",
    "eps = 1e-10\n",
    "\n",
    "# Original spectrogram (in dB)\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.imshow(20 * np.log10(x_abs + eps), origin='lower', aspect='auto', cmap='inferno')\n",
    "plt.title(\"Original Spectrogram |X_norm| (dB)\")\n",
    "plt.xlabel(\"Frames\")\n",
    "plt.ylabel(\"Frequencies\")\n",
    "plt.colorbar()\n",
    "\n",
    "# Quantized spectrogram (in dB)\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.imshow(20 * np.log10(Xq_norm + eps), origin='lower', aspect='auto', cmap='inferno')\n",
    "plt.title(\"Quantized Spectrogram |Xq_norm| (dB)\")\n",
    "plt.xlabel(\"Frames\")\n",
    "plt.ylabel(\"Frequencies\")\n",
    "plt.colorbar()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"Min/Max values in Xq_norm:\", np.min(Xq_norm), np.max(Xq_norm))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bf30042",
   "metadata": {},
   "source": [
    "###  Interpretation of the Quantized Spectrogram\n",
    "\n",
    "The quantized spectrogram clearly shows that the frequencies which mostly disappear are those located beyond the dominant frequency indices (here, beyond indices 1 to 10). These correspond mainly to high frequencies (treble), weak harmonics, and components with very low energy (background noise).\n",
    "\n",
    "The perceptual algorithm allocates more bits to strongly audible components (high energy, high SMR), which are precisely located in these dominant low-frequency regions (indices 1–10 in our example), and fewer or no bits to weak, inaudible, or already masked frequencies (NMR ≤ 0).\n",
    "\n",
    "Thus, the perceptual mechanism focuses information and perceived quality on the frequencies most relevant to the human ear, while efficiently discarding less perceptible frequencies — thereby reducing the bitrate without significantly affecting the subjective sound quality.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e18fcad",
   "metadata": {},
   "source": [
    "# $ Decoding \\space and \\space Decompression $\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1fa9f14",
   "metadata": {},
   "source": [
    "1/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d92921d0",
   "metadata": {},
   "source": [
    "The `Fuquant_inv` function reconstructs an approximate real value from a quantized integer. It acts as the inverse of `Fuquant`, taking into account the sign, the quantization level, and the number of bits `R`. Its role is to decode a compressed signal by mapping the encoded integers back to normalized real values in the range [–1, 1].\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab9f17d8",
   "metadata": {},
   "source": [
    "### Visualization of the Inverse Quantization Function `Fuquant_inv(Fuquant(x))`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fcc4c75",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.linspace(-2, 2, 1000)\n",
    "xq = [Fuquant_inv(Fuquant(val, 4), R=4) for val in x]\n",
    "\n",
    "plt.figure(np.random.randint(1000), figsize=(10, 5))\n",
    "plt.plot(x, xq)\n",
    "plt.title(\"Characteristic Curve of the Composite Function Fuquant_inv(Fuquant(x))\")\n",
    "plt.xlabel(\"x (input)\")\n",
    "plt.ylabel(\"x approx (output)\")\n",
    "plt.grid()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "103f35bf",
   "metadata": {},
   "source": [
    "### Dequantization and Denormalization of the Spectral Matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03e01e94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the decoded/denormalized matrix\n",
    "X_uq = np.zeros_like(Xq_norm)\n",
    "\n",
    "# Loop for dequantization and denormalization\n",
    "for n in range(nb_frames):\n",
    "    for k in range(nb_freqs):\n",
    "        bits = Q_all[k, n]\n",
    "        if bits > 0:\n",
    "            xq = Xq_norm[k, n] * (2 ** (bits - 1))  # Convert back to quantized integer\n",
    "            X_uq[k, n] = Fuquant_inv(xq, bits) * An[n]  # Dequantization + denormalization\n",
    "        else:\n",
    "            X_uq[k, n] = 0  # Silence if no bits were allocated\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7438aa50",
   "metadata": {},
   "source": [
    "### Time-Domain Signal Reconstruction via Inverse STFT\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad719a5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reconstruct the complex spectrogram by reintroducing the phase\n",
    "X_rec_complex = X_uq * np.exp(1j * phase)\n",
    "\n",
    "# Inverse STFT (or iSTFT) to reconstruct the time-domain signal\n",
    "y_rec, t_vect = ITFCT(X_rec_complex, N_win, N_hop, Fs, np.hamming(N_win))\n",
    "\n",
    "# Normalize the reconstructed signal to range [-1, 1]\n",
    "y_rec_norm = y_rec / np.max(np.abs(y_rec))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc343290",
   "metadata": {},
   "source": [
    "### Playback of the Reconstructed Signal After Compression\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04fb06c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Flatten the reconstructed signal\n",
    "y_rec_norm = y_rec.flatten()\n",
    "\n",
    "# Reconstructed signal after compression/decompression\n",
    "print(\"Signal after compression and decompression:\")\n",
    "display(Audio(y_rec_norm, rate=Fs))  # y_rec is the signal reconstructed via ITFCT\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54ac88fd",
   "metadata": {},
   "source": [
    "### Function `test_coding_rate(D)`: Psychoacoustic Bit Allocation and Reconstruction at Target Bitrate\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_coding_rate(D):\n",
    "    # Load and normalize the signal\n",
    "    Fs, x = wavfile.read(\"songs/daftPunk_aroundTheWorld.wav\")\n",
    "    if x.ndim > 1:\n",
    "        x = x[:, 0]\n",
    "    x = x / np.max(np.abs(x))\n",
    "\n",
    "    # STFT parameters\n",
    "    N_win = 2048\n",
    "    N_hop = 1024\n",
    "    Nfft = N_win\n",
    "    x_mat, t_vect, freq_vect = TFCT(N_win, N_hop, Nfft, x, Fs)\n",
    "\n",
    "    phase = np.angle(x_mat)\n",
    "    x_mat_normalised = x_mat.copy()\n",
    "    An = np.max(np.abs(x_mat_normalised), axis=0) + 1e-10\n",
    "    x_mat_normalised = x_mat_normalised / An\n",
    "\n",
    "    # Compute Nmax from the target bitrate D\n",
    "    L = int(np.floor((Fs - N_win) / N_hop + 1))\n",
    "    K1 = int(np.floor((N_win - 1) / N_hop))\n",
    "    left = ((N_win - 1) * K1) / N_win - (N_hop * K1 * (K1 + 1)) / (2 * N_win)\n",
    "    K2 = int(np.floor((Fs - 1) / N_hop - L + 1))\n",
    "    right = (K2 * (Fs - (L - 1) * N_hop)) / N_win - (N_hop * K2 * (K2 + 1)) / (2 * N_win)\n",
    "    N_tr = L + left + right\n",
    "    Nb_trame = D / N_tr\n",
    "    Nmax = int(np.ceil(Nb_trame))\n",
    "    Q_max = 16\n",
    "\n",
    "    # Greedy bit allocation\n",
    "    mask_db = -96\n",
    "    mask_lin = 10 ** (mask_db / 20)\n",
    "    nb_freqs, nb_frames = x_mat_normalised.shape\n",
    "    Q_all = np.zeros_like(x_mat_normalised.real, dtype=int)\n",
    "    threshold_hz = 25000\n",
    "    audible_indices = np.where(freq_vect <= threshold_hz)[0]\n",
    "\n",
    "    for n in range(nb_frames):\n",
    "        X_frame = np.abs(x_mat_normalised[:, n])\n",
    "        SMR = 20 * np.log10(X_frame / mask_lin + 1e-10)\n",
    "        Q = np.zeros(nb_freqs, dtype=int)\n",
    "        SNR = np.zeros(nb_freqs)\n",
    "        NMR = SMR - SNR\n",
    "        Ndb = Nmax\n",
    "\n",
    "        while np.max(NMR[audible_indices]) > 0 and Ndb > 0:\n",
    "            i_local = np.argmax(NMR[audible_indices])\n",
    "            i = audible_indices[i_local]\n",
    "            if Q[i] < Q_max:\n",
    "                Q[i] += 1\n",
    "                SNR[i] += 6\n",
    "                Ndb -= 1\n",
    "                NMR[i] = SMR[i] - SNR[i]\n",
    "            else:\n",
    "                NMR[i] = -np.inf\n",
    "        Q_all[:, n] = Q\n",
    "\n",
    "    # Quantization\n",
    "    x_abs = np.abs(x_mat_normalised)\n",
    "    Xq_norm = np.zeros_like(x_abs)\n",
    "    for n in range(nb_frames):\n",
    "        for k in range(nb_freqs):\n",
    "            bits = Q_all[k, n]\n",
    "            if bits > 0:\n",
    "                Xq_norm[k, n] = Fuquant(x_abs[k, n], bits) / (2 ** (bits - 1) + 1e-10)\n",
    "            else:\n",
    "                Xq_norm[k, n] = 0\n",
    "\n",
    "    # Dequantization\n",
    "    X_uq = np.zeros_like(Xq_norm)\n",
    "    for n in range(nb_frames):\n",
    "        for k in range(nb_freqs):\n",
    "            bits = Q_all[k, n]\n",
    "            if bits > 0:\n",
    "                xq = Xq_norm[k, n] * (2 ** (bits - 1))\n",
    "                X_uq[k, n] = Fuquant_inv(xq, bits) * An[n]\n",
    "            else:\n",
    "                X_uq[k, n] = 0\n",
    "\n",
    "    # Signal reconstruction\n",
    "    X_rec_complex = X_uq * np.exp(1j * phase)\n",
    "    y_rec, _ = ITFCT(X_rec_complex, N_win, N_hop, Fs, np.hamming(N_win))\n",
    "    y_rec_norm = y_rec.flatten() / np.max(np.abs(y_rec))\n",
    "\n",
    "    print(f\"Reconstructed signal for D = {D / 1000} kbps\")\n",
    "    display(Audio(y_rec_norm, rate=Fs))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "debit_test_list = [\n",
    "    64_000,    # very compressed\n",
    "    96_000,    # heavy compression\n",
    "    128_000,   # standard MP3 quality\n",
    "    192_000,   # good trade-off\n",
    "    256_000,   # high quality\n",
    "    320_000,   # high MP3 quality\n",
    "    396_000    # reference maximum\n",
    "]\n",
    "\n",
    "for D in debit_test_list:\n",
    "    test_coding_rate(D)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f86dca8",
   "metadata": {},
   "source": [
    "### Observations on Compression and Decompression Results\n",
    "\n",
    "After compression and decompression, we observe that at low bitrates (64–96 kbps), the signal exhibits significant artifacts. The spectrograms reveal that many components, especially in the high frequencies and low-amplitude harmonics, either disappear or are heavily attenuated due to aggressive bit allocation (elimination of frequencies with low SMR). This leads to audible information loss and a sound that often feels muffled or unclear.\n",
    "\n",
    "At medium bitrates (128–192 kbps), dominant components such as the fundamental and the first harmonics are better preserved, although some subtle details and overall dynamics remain slightly degraded.\n",
    "\n",
    "Finally, at high bitrates (256–396 kbps), the allocation becomes much more generous: the quantized spectrogram closely resembles the original, and the perceptible difference becomes nearly nonexistent. This allows for preservation of the essential auditory information in the signal.\n",
    "\n",
    "Nevertheless, the compression is not perfect: subtle details of the signal are still lost, and a slight “click” sound systematically persists in all compressed files. It remains unclear whether this is due to an inherent limitation of the compression method used or a misconfiguration on my part.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c537a3ca",
   "metadata": {},
   "source": [
    "### Conclusion on Perceptual Bit Allocation and Coding Optimization\n",
    "\n",
    "Perceptual bit allocation leverages the psychoacoustic characteristics of human hearing to concentrate bits on the signal components that are truly audible, as opposed to uniform allocation, which distributes bits equally across all frequencies. By assigning more bits to frequencies with a high signal-to-mask ratio (high SMR) and reducing or eliminating bits for masked or barely perceptible frequencies (where NMR ≤ 0), this approach reduces the bitrate while maintaining a perceived audio quality close to the original.\n",
    "\n",
    "Several improvements can be considered to make the coding process more efficient:\n",
    "\n",
    "- **Improvement of the psychoacoustic model:**  \n",
    "  Incorporating a more accurate model (accounting for both simultaneous and temporal masking) would enable finer and more targeted bit allocation focused on the critical areas of the spectrum.\n",
    "\n",
    "- **Use of entropy coding:**  \n",
    "  Techniques such as Huffman coding or arithmetic coding could reduce redundancy and optimize bit usage.\n",
    "\n",
    "- **Temporal optimization:**  \n",
    "  Dynamically adapting the window size $N_{win}$ and hop size $N_{hop}$ based on local signal characteristics (transients, stability, etc.) could improve resolution and allow more precise bit allocation.\n",
    "\n",
    "- **Optimization of STFT parameters:**  \n",
    "  A well-chosen window size and overlap (e.g., $N_{win} = 2048$ and $N_{hop} = 1024$ for tonal music) provides a good trade-off between frequency and time resolution, thus enhancing the discrimination of audible components.\n",
    "\n",
    "- **Dynamic adaptation of the perceptual mask:**  \n",
    "  In the current algorithm, the masking level is fixed at –96 dB for all signals, which assumes a generic dynamic range (16-bit). However, adapting the masking threshold dynamically based on signal characteristics (RMS level, dynamic range, content type: voice, music, noise, etc.) would allow a better exploitation of human auditory limits.  \n",
    "  For example, a very loud signal could tolerate a higher masking threshold (e.g., –80 dB), while a quieter signal might require a lower threshold (e.g., –100 dB), enabling bit allocation better suited to the context. This would lead to more efficient compression without degrading perceived quality.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b1e6d45",
   "metadata": {},
   "source": [
    "# $ BONUS $ "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58966b73",
   "metadata": {},
   "source": [
    "### Global Uniform Bit Allocation and Audio Comparison\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5485dba5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def global_uniform_encoding(wav_path, Q_bits=6, N_win=2048, N_hop=1024):\n",
    "    # Load the signal\n",
    "    Fs, x = wavfile.read(wav_path)\n",
    "    if x.ndim > 1:\n",
    "        x = x[:, 0]\n",
    "    x = x / np.max(np.abs(x))\n",
    "\n",
    "    # STFT\n",
    "    x_mat, _, _ = TFCT(N_win, N_hop, N_win, x, Fs)\n",
    "    phase = np.angle(x_mat)\n",
    "    x_abs = np.abs(x_mat)\n",
    "    An = np.max(x_abs, axis=0) + 1e-10\n",
    "    x_norm = x_abs / An\n",
    "    nb_freqs, nb_frames = x_abs.shape\n",
    "\n",
    "    # Uniform quantization (with loop)\n",
    "    Xq_norm = np.zeros_like(x_norm)\n",
    "    for n in range(nb_frames):\n",
    "        for k in range(nb_freqs):\n",
    "            Xq_norm[k, n] = Fuquant(x_norm[k, n], Q_bits) / (2 ** (Q_bits - 1) + 1e-10)\n",
    "\n",
    "    # Dequantization (with loop)\n",
    "    X_uq = np.zeros_like(x_norm)\n",
    "    for n in range(nb_frames):\n",
    "        for k in range(nb_freqs):\n",
    "            q_val = Xq_norm[k, n] * (2 ** (Q_bits - 1))\n",
    "            X_uq[k, n] = Fuquant_inv(q_val, Q_bits) * An[n]\n",
    "\n",
    "    # Reconstruction\n",
    "    X_rec = X_uq * np.exp(1j * phase)\n",
    "    y_rec, _ = ITFCT(X_rec, N_win, N_hop, Fs, np.hamming(N_win))\n",
    "    y_rec = y_rec.flatten() / np.max(np.abs(y_rec))\n",
    "\n",
    "    # Playback\n",
    "    print(\"Original signal:\")\n",
    "    display(Audio(x, rate=Fs))\n",
    "\n",
    "    print(f\"Compressed signal (uniform allocation, Q = {Q_bits} bits):\")\n",
    "    display(Audio(y_rec, rate=Fs))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41ba1ba2",
   "metadata": {},
   "source": [
    "### Bandwise Uniform Bit Allocation and Audio Comparison\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d6e5270",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bandwise_uniform_encoding(wav_path, Q_bits=6, band_size=32, N_win=2048, N_hop=1024):\n",
    "    # Load and normalize the signal\n",
    "    Fs, x = wavfile.read(wav_path)\n",
    "    if x.ndim > 1:\n",
    "        x = x[:, 0]\n",
    "    x = x / np.max(np.abs(x))\n",
    "\n",
    "    # STFT\n",
    "    x_mat, _, _ = TFCT(N_win, N_hop, N_win, x, Fs)\n",
    "    phase = np.angle(x_mat)\n",
    "    x_abs = np.abs(x_mat)\n",
    "    An = np.max(x_abs, axis=0) + 1e-10\n",
    "    x_norm = x_abs / An\n",
    "    nb_freqs, nb_frames = x_abs.shape\n",
    "\n",
    "    # Bandwise uniform quantization\n",
    "    Xq_norm = np.zeros_like(x_norm)\n",
    "    for n in range(nb_frames):\n",
    "        for b in range(0, nb_freqs, band_size):\n",
    "            for k in range(b, min(b + band_size, nb_freqs)):\n",
    "                Xq_norm[k, n] = Fuquant(x_norm[k, n], Q_bits) / (2 ** (Q_bits - 1) + 1e-10)\n",
    "\n",
    "    # Dequantization (bandwise)\n",
    "    Xq = np.zeros_like(Xq_norm)\n",
    "    for n in range(nb_frames):\n",
    "        for b in range(0, nb_freqs, band_size):\n",
    "            for k in range(b, min(b + band_size, nb_freqs)):\n",
    "                qval = Xq_norm[k, n] * (2 ** (Q_bits - 1))\n",
    "                Xq[k, n] = Fuquant_inv(qval, Q_bits) * An[n]\n",
    "\n",
    "    # Signal reconstruction\n",
    "    X_rec = Xq * np.exp(1j * phase)\n",
    "    y_rec, _ = ITFCT(X_rec, N_win, N_hop, Fs, np.hamming(N_win))\n",
    "    y_rec = y_rec.flatten() / np.max(np.abs(y_rec))\n",
    "\n",
    "    # Playback\n",
    "    print(\"Original signal:\")\n",
    "    display(Audio(x, rate=Fs))\n",
    "    print(f\"Compressed signal (bandwise, {Q_bits} bits, {band_size} bins):\")\n",
    "    display(Audio(y_rec, rate=Fs))\n",
    "\n",
    "# Example usage\n",
    "bandwise_uniform_encoding(\"songs/daftPunk_aroundTheWorld.wav\", Q_bits=6, band_size=32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3a8986f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of audio files located in the 'sons/' folder (relative paths)\n",
    "files = [\n",
    "    \"songs/suzanneVega_tomsDiner.wav\",\n",
    "    \"songs/daftPunk_aroundTheWorld.wav\",\n",
    "    \"songs/orchestre.wav\"\n",
    "]\n",
    "\n",
    "# Apply global uniform quantization to each file\n",
    "for file_path in files:\n",
    "    print(f\"\\n--- Processing: {file_path} ---\")\n",
    "    global_uniform_encoding(file_path, Q_bits=6)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f3df9fa",
   "metadata": {},
   "source": [
    "### Uniform vs. Perceptual Audio Compression\n",
    "\n",
    "Compressing an audio signal using uniform bit allocation involves assigning the same number of bits to all frequencies, without considering the sensitivity of human hearing. This simple method can produce acceptable sound quality if the bit depth is high, but it quickly becomes inefficient at lower bitrates, as it wastes bits on barely audible frequencies and significantly degrades audio quality. In such cases, detail loss, distortion, and even a metallic sound effect can be observed.\n",
    "\n",
    "In contrast, perceptual compression — used in standards like MPEG (e.g., MP3) — achieves very good audio quality even at low bitrates. It relies on a psychoacoustic model that allocates more bits to important frequencies and drastically reduces the precision of masked or inaudible components. This approach enables efficient compression while maintaining sound reproduction that remains close to the original and adapted to the human ear.\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
